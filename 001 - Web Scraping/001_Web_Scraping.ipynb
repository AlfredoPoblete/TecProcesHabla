{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping\n",
        "Web Scraping es el proceso de recopilar información de forma automática de la Web.\n",
        "\n",
        "Se enfoca en la transformación de datos sin estructura en la web (como el formato HTML) en datos estructurados que pueden ser almacenados y analizados en una base de datos central, en una hoja de cálculo o en alguna otra fuente de almacenamiento.\n",
        "\n",
        "A continuación, se detallará los pasos realizados para la extracción del contenido principal de una página web de interés personal.\n"
      ],
      "metadata": {
        "id": "Ouv5u1phGGXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Importamos Librerias Necesarias\n"
      ],
      "metadata": {
        "id": "xIr1reQa-_7S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F7M5yXa89ra"
      },
      "outputs": [],
      "source": [
        "# Importamos Librerias Necesarias\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "import random\n",
        "from wordcloud import WordCloud\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Conocemos como esta estructurada la página"
      ],
      "metadata": {
        "id": "bry-IKXpK4-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos en una variable la url elegida\n",
        "pagina = \"https://vandal.elespanol.com/retro/retro-castlevania-symphony-of-the-night\""
      ],
      "metadata": {
        "id": "rWFu4x2m_6Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos el contenido de la pagina en una nueva variable y la mostramos\n",
        "contenido = requests.get(pagina).text\n",
        "print(contenido)"
      ],
      "metadata": {
        "id": "M9gQMqI4A9Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - Accedemos a los elementos almacenados en etiquetas HTML"
      ],
      "metadata": {
        "id": "bikfpfJoL_FX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parseamos el contenido con BeautifulSoup\n",
        "bsoup = BeautifulSoup(contenido, \"html.parser\")"
      ],
      "metadata": {
        "id": "FnjMX8giByoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos en una variable el titulo principal de la pagina y lo mostramos\n",
        "h1 = bsoup.find(\"h1\").text\n",
        "print(\"Titulo del contenido de la pagina: \",h1)"
      ],
      "metadata": {
        "id": "QmKCiHF-CCnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos en diferentes variables las correspondientes divisiones de la url para poder mostrar el contenido principal de la pagina\n",
        "div1 = bsoup.find(\"div\",{\"id\": \"globalwrap\"})\n",
        "div2 = div1.find(\"div\",{\"class\": \"fblanco mt1 froboto\"})\n",
        "div3 = div2.find(\"article\",{\"class\": \"articulo container\"})\n",
        "div4 = div3.find(\"div\",{\"class\": \"row mt15\"})\n",
        "div5 = div4.find(\"div\",{\"class\": \"span8\"})\n",
        "parrafos = div5.find_all(\"p\")\n",
        "print(\"Contenido principal de la pagina:\")\n",
        "for parrafo in parrafos:\n",
        "  print(\"\\n\"+parrafo.text.strip())\n",
        "\n"
      ],
      "metadata": {
        "id": "mVEp4yHmCa2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - Analisis de Frecuencias del texto extraido"
      ],
      "metadata": {
        "id": "Ll0LznyqNhNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos la cantidad de veces que se repite una determinada palabra\n",
        "conteo_palabras = str(parrafos)\n",
        "print(\"Cantidad de veces que se repite la palabra 'Dracula': \",conteo_palabras.count(\"Dracula\"),\"Veces\")\n",
        "print(\"Cantidad de veces que se repite la palabra 'Castlevania': \",conteo_palabras.count(\"Castlevania\"),\"Veces\")\n",
        "print(\"Cantidad de veces que se repite la palabra 'Belmont': \",conteo_palabras.count(\"Belmont\"),\"Veces\")\n",
        "print(\"Cantidad de veces que se repite la palabra 'Richter': \",conteo_palabras.count(\"Richter\"),\"Veces\")"
      ],
      "metadata": {
        "id": "zkwjRZTCRf7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcion para buscar palabras\n",
        "def buscar_palabra(palabra):\n",
        "  conteo = str(parrafos).lower().count(palabra.lower())\n",
        "  print(f\"La palabra {palabra} se repite {conteo} veces\")\n",
        "palabra_a_buscar = input(\"Ingrese la palabra a buscar: \")\n",
        "buscar_palabra(palabra_a_buscar)\n",
        "\n",
        "# Creamos un bucle para que el usuario juegue buscando la cantidad de palabras que se repiten del contenido principal\n",
        "while True:\n",
        "  respuesta = input(\"¿Desea buscar otra palabra? (s/n): \").lower()\n",
        "  if respuesta.lower() == \"s\"  :\n",
        "    palabra_a_buscar = input(\"Ingrese la palabra a buscar: \")\n",
        "    buscar_palabra(palabra_a_buscar)\n",
        "  elif respuesta.lower() != \"n\" and respuesta.lower() != \"s\":\n",
        "    print(\"Opcion incorrecta\")\n",
        "  else:\n",
        "    print(\"Gracias por usar el programa\")\n",
        "    break\n"
      ],
      "metadata": {
        "id": "sY_2qOj_U2FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos un Parrafo aleatorio y lo mostramos\n",
        "parrafo_aleatorio = random.choice(parrafos).text.strip()\n",
        "print(parrafo_aleatorio)\n",
        "# imprime la longitud del parrafo aleatoria\n",
        "print(\"Longitud del Parrafo: \",len(parrafo_aleatorio.split()))"
      ],
      "metadata": {
        "id": "c118zP_DOs4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 - Preparamos el texto para graficar una nube de palabras"
      ],
      "metadata": {
        "id": "z0EENgjlO-6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga corpus de stopwords en español\n",
        "nltk.download(\"stopwords\")\n",
        "stopwords_es = set(stopwords.words(\"spanish\"))"
      ],
      "metadata": {
        "id": "EQnBmDKoT9SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcion Para limpiar texto\n",
        "def limpiar_texto(texto):\n",
        "  #Convierte texto en minuscula\n",
        "  texto_minuscula = texto.lower()\n",
        "  texto_sin_puntuacion = re.sub(r\"[^\\w\\s]\", \"\", texto_minuscula) # Elimina todos los signos de puntuacion\n",
        "  lista_palabras = texto_sin_puntuacion.split() # Divide el texto en palabras individuales\n",
        "  palabras_importantes = [] # Crea una lista de palabras importantes\n",
        "  for palabra in lista_palabras:\n",
        "    if palabra not in stopwords_es:\n",
        "      palabras_importantes.append(palabra)\n",
        "  return palabras_importantes\n",
        "\n",
        "texto_completo = bsoup.get_text()\n",
        "palabras_limpias = limpiar_texto(texto_completo)\n",
        "\n",
        "texto_limpio = \" \".join(palabras_limpias)\n"
      ],
      "metadata": {
        "id": "vRkeWzDQY7Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 - Graficamos una nube de palabras"
      ],
      "metadata": {
        "id": "RJbqlu3KPmAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficamos las palabras mas destacadas\n",
        "wordcloud = WordCloud(width=800, height=400, background_color=\"darkred\", colormap = \"viridis\").generate(texto_limpio)\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yEbaRq3lZO6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 - Optimizamos el Grafico"
      ],
      "metadata": {
        "id": "KWpf2C-YP8RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcion Para limpiar texto\n",
        "def limpiar_texto(texto):\n",
        "\n",
        "# Lista de palabras a eliminar\n",
        "\n",
        "  palabras_a_eliminar = ['parte', 'mal', 'después', 'si', 'cada', 'saga', 'momento',\n",
        "        'hoy', 'parte', 'propia', 'toda', 'hoy', 'tan', 'mismo',\n",
        "        'sello', 'aquella', 'hace', 'parte','vandal', 'ello']\n",
        "# Anexa las palabras que quiero eliminar a las stopwords\n",
        "  todas_las_palabras_a_eliminar = stopwords_es.union(palabras_a_eliminar)\n",
        "\n",
        "\n",
        "  #Convierte texto en minuscula\n",
        "  texto_minuscula = texto.lower()\n",
        "  texto_sin_puntuacion = re.sub(r\"[^\\w\\s]\", \"\", texto_minuscula) # Elimina todos los signos de puntuacion\n",
        "  lista_palabras = texto_sin_puntuacion.split() # Divide el texto en palabras individuales\n",
        "  palabras_importantes = [] # Crea una lista de palabras impoirtantes\n",
        "  for palabra in lista_palabras:\n",
        "    if palabra not in todas_las_palabras_a_eliminar:\n",
        "      palabras_importantes.append(palabra)\n",
        "  return palabras_importantes\n",
        "\n",
        "texto_completo = bsoup.get_text()\n",
        "palabras_limpias = limpiar_texto(texto_completo)\n",
        "\n",
        "texto_limpio = \" \".join(palabras_limpias)\n"
      ],
      "metadata": {
        "id": "nkyhlGNRbpgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos las palabras mas destacadas, suprimiendo irrelevantes\n",
        "wordcloud = WordCloud(width=800, height=400, background_color=\"lightblue\", colormap = \"copper\").generate(texto_limpio)\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FCoCvpzUdgWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Script para descargar la imagen\n",
        "wordcloud.to_file(\"Imagen.jpg\") # Guarda la imagen generada con el nombre\n",
        "files.download(\"Imagen.jpg\") # Descarga la imagen\n"
      ],
      "metadata": {
        "id": "ka1710yofLFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este método de visualización muestra la frecuencia con la que aparece una palabra en el cuerpo de texto, haciendo que el tamaño de cada palabra sea proporcional a su frecuencia.\n",
        "\n",
        "Analizando la imagen podemos hacernos la idea de que el contenido principal de la página trata de un juego llamado Castlevania con historia centrado en dos personajes principales: Drácula y Richter"
      ],
      "metadata": {
        "id": "Sqp0aE9DRqkY"
      }
    }
  ]
}
