{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduccion a spaCy\n",
        "\n",
        "Spacy es una librería popular de procesamiento del lenguaje natural (PNL) en Python. Se usa para una amplia gama de tareas como la tokenización, el etiquetado de partes del discurso y el reconocimiento de entidades nombradas."
      ],
      "metadata": {
        "id": "t6ITEMQJwqWx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAQy81vAunMu"
      },
      "outputs": [],
      "source": [
        "# Instalamos Libreria Spacy\n",
        "!pip install spacy -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga un modelo de lenguaje pre-entrenado en español que se utilizará con la librería spaCy\n",
        "!python -m spacy download es_core_news_lg -q"
      ],
      "metadata": {
        "id": "4-ax81wu2Mlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos Librerias\n",
        "import spacy\n",
        "import es_core_news_lg\n",
        "from collections import Counter\n",
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "3pmdnvjBzHFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos un modelo de lenguaje en español pre-entrenado en una variable\n",
        "nlp = spacy.load(\"es_core_news_lg\")\n"
      ],
      "metadata": {
        "id": "GQhCkoGs2002"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Tokenizacion\n",
        "\n",
        "Consiste en dividir el texto de entrada en unidades individuales llamadas tokens. Estos tokens representan las piezas fundamentales del texto, como palabras, números y signos de puntuación."
      ],
      "metadata": {
        "id": "zn5GUUfF7oPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Procesamos una frase con el modelo de lenguaje español de spaCy\n",
        "frase = nlp(u'¿Sabes porque estoy feliz? Estoy feliz, porque estoy en Buenos Aires y estudio Ciencias de Datos e Inteligencia Artificial!')\n",
        "\n",
        "# Para obtener los tokens de la frase\n",
        "print([w.text for w in frase])"
      ],
      "metadata": {
        "id": "OPZdgjeE1f-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos las frecuencias de los tokens\n",
        "freq_tokens = Counter([w.text for w in frase])\n",
        "print(\"Los tokens son : \\n\")\n",
        "for item in frase:\n",
        "  print(f\"[*] '{item}' ==> Frecuencia del token: \",freq_tokens[item.text])"
      ],
      "metadata": {
        "id": "EIRaPbqn5i2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"La frase contiene\", len(frase), \"tokens\")"
      ],
      "metadata": {
        "id": "xGnogNfO_JIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos como esta formada la estructura gramatical de la frase y la función de cada palabra dentro de ella.\n",
        "print(\"Token ==> Funcion Gramatical (POS) ==> Explicacion de etiqueta\\n\",\"-\"*80)\n",
        "for token in frase:\n",
        "  print(f\"'{token.text}' ==>, {token.pos_} ==>, {spacy.explain(token.pos_)}\")\n"
      ],
      "metadata": {
        "id": "t_V2m1Bt_ji0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Lematización\n",
        "\n",
        "Es el proceso de reducir una palabra a su forma base o de diccionario, conocida como lema.\n",
        "\n",
        "La Lematización es importante para el reconocimiento de significado, ya que agrupa diferentes formas de la misma palabra bajo una única representación, simplificando el análisis.\n"
      ],
      "metadata": {
        "id": "MtWfzT-l-O2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tokens ==> Lema\\n\",\"-\"*30)\n",
        "for token in frase:\n",
        "  print(f\"'{token.text}' ==> {token.lemma_}\")\n"
      ],
      "metadata": {
        "id": "5Oj_dT8U_RFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - Visualizacion de Analisis de Dependencias\n",
        "\n",
        "Muestra las relaciones de dependencia entre las palabras de la oracion que queremos analizar, y su estructura gramatical"
      ],
      "metadata": {
        "id": "wIaLfo4LTXut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(frase, style='dep', jupyter=True, options={'distance': 100})\n"
      ],
      "metadata": {
        "id": "fxIaRl1uPTxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(frase, style='ent', jupyter=True)"
      ],
      "metadata": {
        "id": "-yfbkXSnRio-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que identifica con \"Misc\" las palabras compuestas y \"Buenos Aires\" como localizacion"
      ],
      "metadata": {
        "id": "tIe-7PB8aFf2"
      }
    }
  ]
}
